#
# Fission chart configuration
#

## Kubernetes configuration
## For minikube, set this to NodePort, elsewhere use LoadBalancer or ClusterIP.
serviceType: ClusterIP

## For minikube, set this to NodePort, elsewhere use LoadBalancer or ClusterIP.
routerServiceType: LoadBalancer

## Image base repository
## Leave it empty for using existing local image
repository: index.docker.io

## Fission image repository
image: fission/fission-bundle

## Image pull policy
pullPolicy: IfNotPresent

## Fission image version
imageTag: 1.10.0

## Port at which Fission controller service should be exposed
controllerPort: 31313

## Port at which Fission router service should be exposed
routerPort: 31314

## Port at which NATS streaming service should be exposed
## (only if nats enabled and not external)
natsStreamingPort: 31316

## Set to false if you create the namespaces manually
createNamespace: true

## Namespace in which to run fission functions (this is different from
## the release namespace)
functionNamespace: fission-function

## Namespace in which to run fission builders (this is different from
## the release namespace)
builderNamespace: fission-builder

## Enable istio integration
enableIstio: false

fetcher:
  ## Fetcher repository
  image: fission/fetcher
  ## Fetcher image version
  imageTag: 1.10.0

  ## Fetcher is only for to downloading or uploading archive.
  ## Normally, you don't need to change the value here, unless necessary.
  resource:
    cpu:
      requests: "10m"
      ## Low CPU limits will increases the function specialization time.
      limits: ""
    mem:
      requests: "16Mi"
      limits: ""

## Logger config
logger:
  influxdbAdmin: "admin"
  fluentdImageRepository: index.docker.io
  fluentdImage: fluent/fluent-bit
  fluentdImageTag: 1.5.1

  ## Fluent-bit writes/reads itâ€™s own sqlite database to record a history of tracked
  ## files and a state of offsets, this is very useful to resume a state if the ser-
  ## vice is restarted. For Kubernetes environment with constraints like OpenShift,
  ## the containers are limited to write hostPath volume. Hence, we have to enable
  ## security context and set privileged to true.
  enableSecurityContext: false

  ## Enable PodSecurityPolicies to allow privileged container
  ## Only required in some clusters and when enableSecurityContext is true
  podSecurityPolicy:
    enabled: false

    ## Configure additional capabilities
    additionalCapabilities:
    # example values for linkerd
    #- NET_RAW
    #- NET_ADMIN

executor:
  adoptExistingResources: false

## Router config
router:
  deployAsDaemonSet: false
  svcAddressMaxRetries: 5
  svcAddressUpdateTimeout: 30s

  ## Display endpoint access logs
  ## To be aware of enabling logging endpoint access log, it increases
  ## router resource utilization when under heavy workloads.
  displayAccessLog: false

  ## Add annotations for router
  # svcAnnotations:
  #   cloud.google.com/load-balancer-type: Internal

  ## For router to match encoded path.
  ## If true, "/foo%2Fbar" will match the path "/{var}";
  ## Otherwise, it will match the path "/foo/bar".
  useEncodedPath: false

  roundTrip:
    ## If true, router will disable the HTTP keep-alive which result in performance degradation.
    ## But it ensures that router can redirect new coming requests to new function pods.
    ##
    ## If false, router will enable transport keep-alive feature for better performance.
    ## However, the drawback is it takes longer to switch to newly created function pods
    ## if using newdeploy as executor type for function. If you want to preserve the
    ## performance while keeping the short switching time to new function, you can create
    ## an environment with short grace period by setting flag "--graceperiod" (default 360s),
    ## so that kubernetes will be able to reap old function pod quickly.
    ##
    ## For details, see https://github.com/fission/fission/issues/723
    disableKeepAlive: false

    ## The keep-alive period for an active network connection to function pod.
    keepAliveTime: 30s

    ## HTTP transport request timeout
    timeout: 50ms

    ## The length of request timeout will multiply with timeoutExponent after each retry
    timeoutExponent: 2

    ## Max retries times of a failed request
    maxRetries: 10

  ## Sample with a rate per time window (traces/second)
  traceSamplingRate: 0.5

## Message queue trigger config
### NATS Streaming, enabled by default
nats:
  # whether or not to use NATS
  enabled: true

  # if true, don't install NATS, but
  external: false

  # Address of NATS server (domain:port)
  # change from default for external NATS
  hostaddress: "nats-streaming:4222"

  # Authorization token to use with NATS
  authToken: "defaultFissionAuthToken"

  # NATS streaming clusterID
  clusterID: "fissionMQTrigger"

  # Client name registered with NATS streaming
  clientID: "fission"

  # Queue group registered with NATS streaming
  queueGroup: "fission-messageQueueNatsTrigger"

  # The image to use for NATS streaming server
  streamingserver:
    image: nats-streaming

## Azure-storage-queue: enable and configure the details
azureStorageQueue:
  enabled: false
  key: ""
  accountName: ""

## Kafka: enable and configure the details
kafka:
  enabled: false
  # note: below link is only for reference.
  # Please use the brokers link for your kafka here.
  brokers: "broker.kafka:9092" # or your-bootstrap-server.kafka:9092/9093
  authentication:
    tls:
      enabled: false
      caCert: "" # path to certificate containing public key of CA authority
      userCert: "" # path to certificate containing public key of the user signed by CA authority
      userKey: "" # path to private key of the user


  # brokers: 'my-broker.kafka:9092' # or my-bootstrap-server.kafka:9092/9093
  # Sample config for authentication
  #   authentication:
  #   tls:
  #     enabled: true
  #     caCert: 'auth/kafka/ca.crt'
  #     userCert: 'auth/kafka/user.crt'
  #     userKey: 'auth/kafka/user.key'

  ## version of Kafka broker
  ## For 0.x it must be a string in the format
  ## "major.minor.veryMinor.patch" example: 0.8.2.0
  ## For 1.x it must be a string in the format
  ## "major.major.veryMinor" example: 2.0.1
  ## Should be >= 0.11.2.0 to enable Kafka record headers support
  # version: "0.11.2.0"

## Persist data to a persistent volume.
persistence:
  ## If true, fission will create/use a Persistent Volume Claim unless storageType is set to s3
  ## If false, use emptyDir
  ##
  enabled: true

  ## Must be set to either local or S3.
  ## If storateType is set(other than local), one of its backend configuration must be set as below.
  #storageType: local | s3

  ## Sample configruation for AWS s3 storage backend
  #s3:
  # bucketName: <awsBucketName>
  # subDir: <sub directory within a bucket>
  # accessKeyId: <awsAccessKeyId>
  # secretAccessKey: <awsSecretAccessKey>
  # region: <awsRegion>

  ## A manually managed Persistent Volume Claim name
  ## Requires persistence.enabled: true
  ## If defined, PVC must be created manually before volume will be bound
  ##
  # existingClaim:

  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner. (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"

  accessMode: ReadWriteOnce
  size: 8Gi

## Extend the container specs for the core fission pods.
## Can be used to add things like affinty/tolerations/nodeSelectors/etc.
## For example:
## extraCoreComponentPodConfig:
##   affinity:
##     nodeAffinity:
##       requiredDuringSchedulingIgnoredDuringExecution:
##         nodeSelectorTerms:
##           - matchExpressions:
##             - key: capability
##               operator: In
##               values:
##                 - app
#extraCoreComponentPodConfig:
#  affinity:
#  tolerations:
#  nodeSelector:

## Analytics let us count how many people installed fission. Set to
## false to disable analytics.
analytics: true

## Internally used for generating an analytics job for non-helm installs
analyticsNonHelmInstall: false

## Enable Heapster only in clusters where heapster does not exist already
heapster: false

## Enable InfluxDB
influxdb:
  enabled: true
  image: influxdb:1.7

# Allow user to override busybox image used in fluent-bit init container
busyboxImage: busybox

## Archive pruner is a garbage collector for archives on the fission storage service.
## This interval configures the frequency at which it runs inside the storagesvc pod.
## The value is in minutes.
pruneInterval: 60

## Fission pre-install/pre-upgrade checks live in this image
preUpgradeChecksImage: fission/pre-upgrade-checks

## if there are any pod specialization errors when a function is triggered and this flag is set to true, the error
## summary is returned as part of http response
debugEnv: false

## Prometheus for scrapping service metrics
prometheus:
  ## set this flag to true if prometheus needs to be deployed along with fission
  enabled: true

  ## If enabled is false, please assign the prometheus service URL
  ## that is accessible by components.
  serviceEndpoint: ""

## set this flag to false if you dont need canary deployment feature
canaryDeployment:
  enabled: true

# Use these flags to enable opentracing, the variable is endpoint of Jaeger collector in the format shown below
#traceCollectorEndpoint: "http://jaeger-collector.jaeger.svc:14268/api/traces?format=jaeger.thrift"
#traceSamplingRate: 0.75

## Message Queue Trigger Kind, KEDA: enable and configuration
mqt_keda:
  enabled: false
  connector_images:
    kafka:
      image: fission/keda-kafka-http-connector
      tag: 1
    rabbitmq:
      image: fission/keda-rabbitmq-http-connector
      tag: 1
